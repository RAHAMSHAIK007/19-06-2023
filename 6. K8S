DAY-01:

KUBERNETES:
Its an alternative tool for docker swarm.
shortcut is k8s.
we have some limitations on docker swarm so we are using now k8s.

INTRO:
opensource platfrom written on go lang used to manage containers.
google invented it on 2014 but later given to cncf & initial version is 2015 

COMPONENTS:
ARCHITECTURE: CNPCA

MASTER NODE:
1. API SERVER: Used to communicate with k8s cluster.
2. ETCD: DB for k8s cluster.it store complete info of cluster.
3. SCHEDULER: used to schdule pods on worker nodes based on hw.
4. CONTROLLER: It will control the components of k8s.

WORKER NODE:
1. KUBELET: Its an agent, which infrom all actions to master.
2. KUBEPROXY: It deals with networking.
3. PODS: group of containers.

TYPES OF CLUSTER:
1. SELFMANAGED:
A. MINIKUBE: 
ITS A SINGLE NODE CLUSTER (MASTER & WORKER)
IN REAL TIME WE USE IT FOR DEV AND TEST ENVS.
NOTE: IT WILL NOT USED ON PROD.

MINIKUBE SETUP:

vim minikube.sh

sudo apt update -y
sudo apt upgrade -y
sudo apt install curl wget apt-transport-https -y
sudo curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
sudo curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64
sudo mv minikube-linux-amd64 /usr/local/bin/minikube
sudo chmod +x /usr/local/bin/minikube
sudo minikube version
sudo curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
sudo curl -LO "https://dl.k8s.io/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl.sha256"
sudo echo "$(cat kubectl.sha256) kubectl" | sha256sum --check
sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
sudo minikube start --driver=docker --force

sh minikube.sh

=====================================
PODS:
its a group of containers.
k8s will work with pods only, it dont know about containers.
pod is the basic unit of deployment in k8s.

KUBECTL: its a tool used to execute commands on k8s cluster.

CREATION OF PODS:

1. IMPERATIVE METHOD: Through commands
2. DECLARATIVE METHOD: Through files (manifest files)

IMPERATIVE:
To create a pod		:kubectl run pod1 --image httpd
To list pods		:kubectl get po/pod/pods
To show addtional info	:kubectl get po -o wide
To show complete info	:kubectl describe pod pod1
To delete the pod	:kubectl delete pod pod1

DECLARATIVE:

vim abc.yml

apiVersion: v1
kind: Pod
metadata:
  name: pod1
spec:
  containers:
    - name: cont1
      image: nginx

kubectl create -f abc.yml


HISTORY:

  1  vim minikube.sh
    2  sh minikube.sh
    3  minikube status
    4  kubectl run pod1 --image httpd
    5  kubectl get pods
    6  kubectl get pod
    7  kubectl get po
    8  kubectl get po/pod/pods
    9  kubectl get po -o wide
   10  kubectl describe pod pod1
   11  kubectl delete pod pod1
   12  kubectl run pod1 --image rahamshaik/trainservice:latest
   13  kubectl get po
   14  kubectl get po -o wide
   15  kubectl describe pod pod1
   16  kubectl delete pod pod1
   17  vim abc.yml
   18  kubectl create -f abc.yml
   19  kubectl get po
   20  kubectl describe pod pod1
   21  kubectl delete pod pod1
   22  history

====================================DAY-02: REPLICASET. LABELS & SELECTORS, DEPLOYMENT & KUBECOLRO, SCALING

REPLICASET:
It will create replicas of pod.
if we delete one pod it will create another one.
all pods will have same application inside it.


LABELS: is used to craete the particular pods as a single unit.
SELECTOR: Used to select pods with same labels.


vim replicaset.yml

apiVersion: apps/v1
kind: ReplicaSet
metadata:
  labels:
    app: swiggy
  name: swiggy-rs
spec:
  replicas: 3
  selector:
    matchLabels:
      app: swiggy
  template:
    metadata:
      labels:
        app: swiggy
    spec:
      containers:
      - name: cont1
        image: nginx


To list rs		:kubectl get rs/replicaset
To show addtional info	:kubectl get rs -o wide
To show complete info	:kubectl describe rs name-of-rs
To delete the rs	:kubectl delete rs name-of-rs

SCALING THE RS:
SCALE-UP: kubectl scale rs/swiggy-rs --replicas=10
SCALE-DOWN: kubectl scale rs/swiggy-rs --replicas=5

NOTE: It follows LIFO in deletion.

DRAWBACK:
it will not useful if application is update.
we need to update image manually one by one to rs.

DEPLOYMENT:
it is advannce than replicaset, used to update pods all at a time.
in real time we create deployments only.

deployment -- > rs -- > pods

vim abc.yml

apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: swiggy
  name: swiggy-deploy
spec:
  replicas: 3
  selector:
    matchLabels:
      app: swiggy
  template:
    metadata:
      labels:
        app: swiggy
    spec:
      containers:
      - name: cont1
        image: nginx

kubectl create -f abc.yml
kubectl get deploy
kubectl get rs
kubectl get po
kubectl get po --show-labels

NOTE: when we update image old pods will deleted new pods will create.

TO UPDATE IMAGE: kubectl edit deploy/swiggy-deploy
kubectl describe deploy swiggy-deploy

KUBECOLOR:

wget https://github.com/hidetatz/kubecolor/releases/download/v0.0.25/kubecolor_0.0.25_Linux_x86_64.tar.gz
tar -zxvf kubecolor_0.0.25_Linux_x86_64.tar.gz
./kubecolor
chmod +x kubecolor
mv kubecolor /usr/local/bin/
kubecolor get po


HISTORY:

  1  vim minikube.sh
    2  sh minikube.sh
    3  kubectl run swiggy --image httpd
    4  kubectl get po
    5  kubectl delete pod swiggy
    6  kubectl get po
    7  vim abc.yml
    8  kubectl api-resources
    9  vim abc.yml
   10  kubectl create -f abc.yml
   11  vim abc.yml
   12  kubectl create -f abc.yml
   13  vim abc.yml
   14  kubectl create -f abc.yml
   15  kubectl api-resources
   16  kubectl get rs
   17  kubectl get rs -o wide
   18  kubectl describe rs swiggy-rs
   19  kubectl get po
   20  kubectl delete pod swiggy-rs-8pp9q
   21  kubectl get po
   22  kubectl delete po swiggy-rs-vqhrm
   23  kubectl get po
   24  kubectl delete pod swiggy-rs-2p6zs swiggy-rs-dbpwf swiggy-rs-rvzgt
   25  kubectl get po
   26  cat abc.yml
   27  kubectl get replicaset
   28  kubectl get rs
   29  kubectl delete rs swiggy-rs
   30  kubectl get rs
   31  kubectl get po
   32  kubectl create -f abc.yml
   33  kubectl get po
   34  kubectl scale rs/swiggy-rs --replicas=10
   35  kubectl get po
   36  kubectl scale rs/swiggy-rs --replicas=20
   37  kubectl get po
   38  kubectl scale rs/swiggy-rs --replicas=5
   39  kubectl get po
   40  cat abc.yml
   41  vim abc.yml
   42  kubectl create -f abc.yml
   43  kubectl get deploy
   44  kubectl get rs
   45  kubectl get po
   46  kubectl describe deploy swiggy-deploy
   47  kubectl edit deploy/swiggy-deploy
   48  kubectl describe deploy swiggy-deploy
   49  kubectl get po
   50  kubectl describe pod swiggy-deploy-9cc566b54-mcwbv
   51  kubectl describe pod swiggy-deploy-9cc566b54-rtj8t
   52  kubectl decsribe pod swiggy-deploy-9cc566b54-xwcqs
   53  kubectl describe pod swiggy-deploy-9cc566b54-xwcqs
   54  kubectl edit deploy/swiggy-deploy
   55  kubectl describe pod swiggy-deploy-9cc566b54-xwcqs
   56  kubectl describe deploy swiggy-deploy
   57  kubectl get po
   58  kubectl describe pod swiggy-deploy-7fdfcb7ffb-9p87n
   59  kubectl describe pod swiggy-deploy-7fdfcb7ffb-h6m9b
   60  kubectl get deploy
   61  kubectl scale deploy/swiggy-deploy --replicas=10
   62  kubectl get po
   63  kubectl get po --show-labels
   64  wget https://github.com/hidetatz/kubecolor/releases/download/v0.0.25/kubecolor_0.0.25_Linux_x86_64.ta                                                                                                                                                                                                                                                                      r.gz
   65  tar -zxvf kubecolor_0.0.25_Linux_x86_64.tar.gz
   66  ./kubecolor
   67  chmod +x kubecolor
   68  mv kubecolor /usr/local/bin/
   69  kubecolor get po
   70  kubecolor get deploy
   71  history

=============================================================================

DAY-03: KOPS

INFRA: Resources used to run our application on cloud.
ex: ec2, elb, asg, vpc ------

KOPS:
It is kubernetes operations.
create, delete, update the cluster.
currently aws and gcp is supporting.
automate the entire infrastructure for k8s.
its 3rd party tool free and opensource.


IAM -- > USERS -- > USERNAME: KOPSRAHAM -- > Attach policies directly -- > AdministratorAccess -- > next -- > create 

click -- > rahamkopss -- > security creds -- > Access keys -- > create access key -- > cli -- > select checkbox -- > next -- > create access key -- > download


SETUP:

PART-1: DOWNLOADING, MV AND GIVING PERMISSIONS


#vim .bashrc
#export PATH=$PATH:/usr/local/bin/
#source .bashrc


#! /bin/bash
aws configure
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
wget https://github.com/kubernetes/kops/releases/download/v1.25.0/kops-linux-amd64
chmod +x kops-linux-amd64 kubectl
mv kubectl /usr/local/bin/kubectl
mv kops-linux-amd64 /usr/local/bin/kops


PART-2: CREATING BUCKET TO STORE CLUSTER INFO

bucket is used to store objects(files)
versioning means it will retrive the deleted files.

aws s3api create-bucket --bucket heerashaik09.k8s.local --region us-east-1
aws s3api put-bucket-versioning --bucket heerashaik09.k8s.local --region us-east-1 --versioning-configuration Status=Enabled
export KOPS_STATE_STORE=s3://heerashaik09.k8s.local

 
PART-3: CREATING CLUSTER

kops create cluster --name heerashaik09.k8s.local --zones us-east-1a --master-count=1 --master-size t2.medium --node-count=2 --node-size t2.micro
kops update cluster --name heerashaik09.k8s.local --yes --admin
kops validate cluster --wait 10m

SCALING THE CLUSTER:

 * list clusters with: kops get cluster
 * edit this cluster with: kops edit cluster heerashaik09.k8s.local
 * edit your node instance group: kops edit ig --name=heerashaik09.k8s.local nodes-us-east-1a
 * edit your master instance group: kops edit ig --name=heerashaik09.k8s.local master-us-east-1a

kops edit ig --name=heerashaik09.k8s.local nodes-us-east-1a
kops update cluster --name heerashaik09.k8s.local --yes
kops rolling-update cluster

TO DELET CLUTSTER: kops delete cluster --name heerashaik09.k8s.local --yes

HISTORY:

 1  aws configure
    2  curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
    3  wget https://github.com/kubernetes/kops/releases/download/v1.25.0/kops-linux-amd64
    4  chmod +x kops-linux-amd64 kubectl
    5  mv kubectl /usr/local/bin/kubectl
    6  mv kops-linux-amd64 /usr/local/bin/kops
    7  kops --version
    8  kubectl --version
    9  vim .bashrc
   10  source .bashrc
   11  kops --version
   12  kubectl --version
   13  kubectl
   14  aws s3api create-bucket --bucket rahamssshaik09.k8s.local --region us-east-1
   15  vim .aws/credentials
   16  aws s3api create-bucket --bucket rahamssshaik09.k8s.local --region us-east-1
   17  aws s3api create-bucket --bucket heerashaik09.k8s.local --region us-east-1
   18  aws s3api put-bucket-versioning --bucket heerashaik09.k8s.local --region us-east-1 --versioning-configuration Status=Enabled
   19  export KOPS_STATE_STORE=s3://heerashaik09.k8s.local
   20  kops create cluster --name heerashaik09.k8s.local --zones us-east-1a --master-count=1 --master-size t2.medium --node-count=2                                                                                                                                                                                 --node-size t2.micro
   21  kops update cluster --name heerashaik09.k8s.local --yes --admin
   22  kops validate cluster --wait 10m
   23  kops edit ig --name=heerashaik09.k8s.local nodes-us-east-1a
   24  kops update cluster --name heerashaik09.k8s.local --yes
   25  kops rolling-update cluster
   26  kops edit ig --name=heerashaik09.k8s.local nodes-us-east-1a
   27  kops rolling-update cluster
   28  kops update cluster --name heerashaik09.k8s.local --yes
   29  kops rolling-update cluster
   30  kops edit ig --name=heerashaik09.k8s.local nodes-us-east-1a
   31  kops update cluster --name heerashaik09.k8s.local --yes
   32  kops rolling-update cluster
   33  kops edit ig --name=heerashaik09.k8s.local nodes-us-east-1a
   34  kops update cluster --name heerashaik09.k8s.local --yes
   35  kops rolling-update cluster
   36  kubectl get no
   37  kops get cluster
   38  kubectl get no
   39  vim deploy.yml
   40  kubectl create -f deploy.yml
   41  kubectl get po
   42  kubectl get po -o wide
   43  kubectl scale deploy/swiggy-deploy --replicas=9
   44  kubectl get po -o wide
   45  kubectl scale deploy/swiggy-deploy --replicas=12
   46  kubectl get po -o wide
   47  kops delete cluster --name heerashaik09.k8s.local --yes
   48  history
  =====================================================================================


CREATING CLUSTER USING THE SHELL SCRIPT:

#vim .bashrc
#export PATH=$PATH:/usr/local/bin/
#source .bashrc


#! /bin/bash
aws configure
curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
wget https://github.com/kubernetes/kops/releases/download/v1.25.0/kops-linux-amd64
chmod +x kops-linux-amd64 kubectl
mv kubectl /usr/local/bin/kubectl
mv kops-linux-amd64 /usr/local/bin/kops

aws s3api create-bucket --bucket rahamssshaik09.k8s.local --region us-east-1
aws s3api put-bucket-versioning --bucket rahamssshaik09.k8s.local --region us-east-1 --versioning-configuration Status=Enabled
export KOPS_STATE_STORE=s3://rahamssshaik09.k8s.local
kops create cluster --name rahams.k8s.local --zones us-east-1a --master-count=1 --master-size t2.medium --node-count=2 --node-size t2.micro
kops update cluster --name rahams.k8s.local --yes --admin


Namespace: in real time inside a cluster multiple teams will work
we need to give some workspace to each team
so we create namespaces.

it is used to isolate the cluster from one team to another team.


============================================================================


NAMESPACE: It is used to divide the cluster to multiple teams on real time.

CLUSTER: HOUSE
ROOM: NAMESPACES

Each namespace is isolated.
if your are room-1 are you able to see room-2.
we cant access the objects from one namespace to another namespace.


TYPES:

default           : Is the default namespace, all objects will create here only
kube-node-lease   : it will store object which is taken from one namespace to another.
kube-public	  : all the public objects will store here.      
kube-system 	  : default k8s will create some objects, those are storing on this ns.


kubectl create ns dev	: to create namespace
kubectl config set-context --current --namespace=dev : to switch to the namespace
kubectl config view --minify | grep namespace : to see current namespace
kubectl delete ns dev	: to delete namespace

NOTE: By deleting  the ns all objects also gets deleted.

==========================================================================================================

SERVICE: It is used to expose the application in k8s.



TYPES:
1. CLUSTERIP: It will work inside the cluster.
it will not expose to outer world.

apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: swiggy
  name: swiggy-deploy
spec:
  replicas: 3
  selector:
    matchLabels:
      app: swiggy
  template:
    metadata:
      labels:
        app: swiggy
    spec:
      containers:
      - name: cont1
        image: rahamshaik/trainservice:latest
        ports:
          - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: sv1
spec:
  type: ClusterIP
  selector:
    app: swiggy
  ports:
    - port: 80

DRAWBACK:
We cannot use app outside.

2. NODEPORT: It will expose our application in a particular port.
Range: 30000 - 32767 (in sg we need to give all traffic)

apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: swiggy
  name: swiggy-deploy
spec:
  replicas: 3
  selector:
    matchLabels:
      app: swiggy
  template:
    metadata:
      labels:
        app: swiggy
    spec:
      containers:
      - name: cont1
        image: rahamshaik/trainservice:latest
        ports:
          - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: abc
spec:
  type: NodePort
  selector:
    app: swiggy
  ports:
    - port: 80
      targetPort: 80
      nodePort: 31111


NOTE: UPDATE THE SG (REMOVE OLD TRAFFIC AND GIVE ALL TRAFFIC & SSH)
DRAWBACK:
PORT RESTRICTION.

3. LOADBALACER: It will expose our app and distribute load blw pods.

apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: swiggy
  name: swiggy-deploy
spec:
  replicas: 3
  selector:
    matchLabels:
      app: swiggy
  template:
    metadata:
      labels:
        app: swiggy
    spec:
      containers:
      - name: cont1
        image: rahamshaik/trainservice:latest
        ports:
          - containerPort: 80
---
apiVersion: v1
kind: Service
metadata:
  name: abc
spec:
  type: LoadBalancer
  selector:
    app: swiggy
  ports:
    - port: 80
      targetPort: 80

KUBEADM: It is multi node cluster used to work with k8s.
The worst tool.
everything we need to create manually.
ec2, vpc, sg, lb, asg ---------





history:

    1  vim .bashrc
    2  source .bashrc
    3  vim kops.sh
    4  sh kops.sh
    5  kops validate cluster --wait 10m
    6  cat kops.sh
    7  export KOPS_STATE_STORE=s3://swiggyzomato.k8s.local
    8  kops validate cluster --wait 10m
    9  kubectl get ns
   10  kubectl get po
   11  kubectl get po -n kubesystem
   12  kubectl get po -n kube-system
   13  kubectl get po
   14  kubectl get po -n kube-system
   15  kubectl run pod1 --image nginx
   16  kubectl describe pod pod1
   17  kubectl get ns
   18  kubectl create ns dev
   19  kubectl get ns
   20  kubectl config view --minify
   21  kubectl config view --minify |grep -i namespace
   22  kubectl view config --minify
   23  kubectl config view
   24  kubectl config view --minify
   25  kubectl config view --minify | grep namespace
   26  kubectl config view --minify | grep namespace:
   27  kubectl config set-context --current --namespace=dev
   28  kubectl config view --minify | grep namespace:
   29  kubectl config view --minify
   30  kubectl get po
   31  kubectl run dev1 --image nginx
   32  kubectl run dev2 --image nginx
   33  kubectl run dev3 --image nginx
   34  kubectl get po
   35  kubectl create ns test
   36  kubectl config set-context --current --namespace=test
   37  kubectl get po
   38  kubectl get po -n dev
   39  kubectl descrive pod dev1
   40  kubectl describe pod dev1
   41  kubectl describe pod dev1 -n dev
   42  kubectl describe pod dev1 -n test
   43  kubectl gete ns
   44  kubectl get ns
   45  kubectl delete ns dev
   46  kubectl delete ns test
   47  vim abc.yml
   48  kubectl create -f abc.yml
   49  kubectl config view --minify
   50  kubectl config set-context --current --namespace=default
   51  kubectl get ns
   52  kubectl create -f abc.yml
   53  kubectl get deploy,svc
   54  kubectl get po -o wide
   55  curl http://3.95.163.7:80
   56  kubectl delete -f abc.yml
   57  vim abc.yml
   58  kubectl apply -f abc.yml
   59  kubectl get deploy,svc
   60  kubectl get po -o wide
   61  vim abc.yml
   62  kubectl apply -f abc.yml
   63  kubectl get deploy,svc
   64  kubectl get po
   65  kubectl delete -f abc.yml
   66  vim abc.yml
   67  kubectl create -f abc.yml
   68  kubectl get deploy,svc
   69  kubectl api-resources
   70  kubectl api-resources | grep -i service
   71  history
[root@ip-172-31-38-37 ~]#



